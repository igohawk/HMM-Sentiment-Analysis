{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igohawk/machine-learning-project/blob/master/Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uJ573W7PlWwL",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "d6f4991c-b934-47bf-e743-b8995ac9d4df"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b16df1b5-152f-4688-953a-df890fc57d17\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b16df1b5-152f-4688-953a-df890fc57d17\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving CN.zip to CN.zip\n",
            "Saving EN.zip to EN.zip\n",
            "Saving FR.zip to FR.zip\n",
            "Saving SG.zip to SG.zip\n",
            "User uploaded file \"CN.zip\" with length 555571 bytes\n",
            "User uploaded file \"EN.zip\" with length 46015 bytes\n",
            "User uploaded file \"FR.zip\" with length 80542 bytes\n",
            "User uploaded file \"SG.zip\" with length 1282785 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wyuRyuOsn6aw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('./CN.zip', 'r')\n",
        "zip_ref.extractall('./CN')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTfFyKQtnrhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_tuple(file):\n",
        "\n",
        "    data = []\n",
        "    lst = []\n",
        "    with open(file, \"r\") as f:\n",
        "        for line in f:\n",
        "            if line == \"\\n\":\n",
        "              data.append(lst)\n",
        "              lst = []\n",
        "            \n",
        "            else:\n",
        "              lines = line.replace(\"\\n\",'').split(\" \")\n",
        "              lst.append(tuple(lines))\n",
        "            \n",
        "    return data\n",
        "\n",
        "\n",
        "  \n",
        "data_tuple('SG/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65c0q-Oss-2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write a function that estimates the emission parameters from the training set using MLE (maximum\n",
        "# likelihood estimation):\n",
        "# e(x|y) = Count(y -> x)/Count(y)\n",
        "# with key <word, tag>\n",
        "\n",
        "def emission_parameter(data):\n",
        "    \n",
        "    tag_count = {}\n",
        "    match_count = {}\n",
        "    \n",
        "    for lst in data:         \n",
        "        for wordTuples in lst:\n",
        "            \n",
        "            tag = wordTuples[1]\n",
        "            \n",
        "            tag_count[tag] = tag_count.get(tag, 0) + 1\n",
        "            match_count[wordTuples] = match_count.get(wordTuples, 0) + 1\n",
        "            \n",
        "      \n",
        "    em = {i: match_count[i]/tag_count[i[1]] for i in match_count}   \n",
        "    return tag_count, em\n",
        "  \n",
        "emission_parameter(data_tuple('SG/train'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emJToYLTBlyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# During the testing phase, if the word does not appear in the training set, we replace that word with the\n",
        "# special word token #UNK#\n",
        "\n",
        "# Set k to 1:\n",
        "\n",
        "def smoothing_em(data, k):\n",
        "\n",
        "    new_data = []\n",
        "    new_tweets = []\n",
        "  \n",
        "    word_count = {}\n",
        "    \n",
        "    for lst in data:\n",
        "        for wordTuples in lst:\n",
        "          \n",
        "            word = wordTuples[0]\n",
        "            tag = wordTuples[1]\n",
        "            \n",
        "            word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "            if word_count[word] < k:\n",
        "              \n",
        "               new_tweets.append((\"#UNK#\",tag))\n",
        "                \n",
        "            else:\n",
        "              \n",
        "                new_tweets.append(wordTuples)\n",
        "                \n",
        "        new_data.append(new_tweets)\n",
        "        new_tweets = []\n",
        "        \n",
        "    return new_data,word_count\n",
        "\n",
        "emission_parameter(smoothing_em(data_tuple('SG/train'),1)[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlLiGmCqI6LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb54926c-415d-42c4-8b56-5b80c7627559"
      },
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(word, tags, em):\n",
        "    \n",
        "    pre_set = (word, \"O\") # if word not in train set, set tag to 0\n",
        "    max_em = 0\n",
        "    \n",
        "    for tag in tags:\n",
        "        if (word, tag) in em.keys():\n",
        "            if em[(word, tag)] > max_em: # to select the max em value\n",
        "                pre_set = (word, tag)\n",
        "                max_em = em[(word, tag)]\n",
        "    return pre_set\n",
        "\n",
        "\n",
        "\n",
        "word = \"hell\"\n",
        "tags = emission_parameter(data_tuple('SG/train'))[0].keys()\n",
        "em = emission_parameter(smoothing_em(data_tuple('SG/train'),1)[0])[1]\n",
        "\n",
        "sentiment_analysis(word,tags,em)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hell', 'B-negative')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "metadata": {
        "id": "9KXFNvP4WbYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Implement a simple sequence labeling system that produces the tag\n",
        "\n",
        "# for each word x in the sequence.\n",
        "\n",
        "def tag_predict(language, q, words, tags, em):\n",
        "   \n",
        "    input_file = language + \"/dev.in\"\n",
        "    output_file = language + \"/dev.p\"+ q +\".out\"\n",
        "    \n",
        "    with open(input_file, \"r\") as f:\n",
        "        with open(output_file, \"w\") as output:\n",
        "            for line in f:\n",
        "                if line ==\"\\n\":\n",
        "                    output.write(\"\\n\")\n",
        "                    continue\n",
        "                    \n",
        "                if line.replace(\"\\n\",\"\") in words:\n",
        "                    test_word = line.replace(\"\\n\",\"\")\n",
        "                    pre_set = sentiment_analysis(test_word, tags, em)\n",
        "                    output.write(\" \".join(pre_set)+\"\\n\")\n",
        "                else:\n",
        "                    output.write(\"#UNK# O\\n\")\n",
        "        #files.download(output_file)\n",
        "        \n",
        "# words = smoothing_em(data_tuple(tf),1)[1].keys()\n",
        "# tags = emission_parameter(data_tuple(tf))[0].keys()\n",
        "# em = emission_parameter(smoothing_em(data_tuple(tf),1)[0])[1]\n",
        "# tf = language + \"/train\"\n",
        "# language = \"SG\"\n",
        "\n",
        "# tag_predict(language,\"2\",words,tags,em)                    \n",
        "                    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0DhO-b2hy7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "def get_entities(observed, sep=' ', output_col=1):\n",
        "\n",
        "    example = 0\n",
        "    word_index = 0\n",
        "    entity = []\n",
        "    last_ne = 'O'\n",
        "    last_sent = ''\n",
        "    last_entity = []\n",
        "\n",
        "    observations = {}\n",
        "    observations[example] = []\n",
        "\n",
        "    for line in observed:\n",
        "        line = line.strip()\n",
        "        if line.startswith('##'):\n",
        "            continue\n",
        "        elif len(line) == 0:\n",
        "            if entity:\n",
        "                observations[example].append(list(entity))\n",
        "                entity = []\n",
        "\n",
        "            example += 1\n",
        "            observations[example] = []\n",
        "            word_index = 0\n",
        "            last_ne = 'O'\n",
        "            continue\n",
        "\n",
        "        split_line = line.split(sep)\n",
        "        value = split_line[output_col]\n",
        "        ne = value[0]\n",
        "        sent = value[2:]\n",
        "\n",
        "        last_entity = []\n",
        "\n",
        "        # check if it is start of entity\n",
        "        if ne == 'B' or (ne == 'I' and last_ne == 'O') or \\\n",
        "                (ne == 'I' and last_ne != 'O' and last_sent != sent):\n",
        "            if entity:\n",
        "                last_entity = entity\n",
        "            entity = [sent]\n",
        "            entity.append(word_index)\n",
        "        elif ne == 'I':\n",
        "            entity.append(word_index)\n",
        "        elif ne == 'O':\n",
        "            if last_ne == 'B' or last_ne == 'I':\n",
        "                last_entity = entity\n",
        "            entity = []\n",
        "\n",
        "        if last_entity:\n",
        "            observations[example].append(list(last_entity))\n",
        "            last_entity = []\n",
        "\n",
        "        last_ne = ne\n",
        "        last_sent = sent\n",
        "        word_index += 1\n",
        "\n",
        "    if entity:\n",
        "        observations[example].append(list(entity))\n",
        "\n",
        "    return observations\n",
        "\n",
        "\n",
        "def compare_result(observed, predicted):\n",
        "    \n",
        "    total_observed = 0\n",
        "    total_predicted = 0\n",
        "    correct = {'Entities': 0, 'Sentiment': 0}\n",
        "\n",
        "    for example in observed:\n",
        "        observed_instance = observed[example]\n",
        "        predicted_instance = predicted[example]\n",
        "        total_observed += len(observed_instance)\n",
        "        total_predicted += len(predicted_instance)\n",
        "\n",
        "        for span in predicted_instance:\n",
        "            span_sent = span[0]\n",
        "            span_ne = (span[1], len(span) - 1)\n",
        "\n",
        "            for observed_span in observed_instance:\n",
        "                sent = observed_span[0]\n",
        "                ne = (observed_span[1], len(observed_span) - 1)\n",
        "\n",
        "                if span_ne == ne:\n",
        "                    correct['Entities'] += 1\n",
        "                    if span_sent == sent:\n",
        "                        correct['Sentiment'] += 1\n",
        "\n",
        "    print('Entities:')\n",
        "    print('In gold-standard outputs: %d' % total_observed)\n",
        "    print('In prediction outputs: %d' % total_predicted)\n",
        "    print()\n",
        "    for t in ('Entities', 'Sentiment'):\n",
        "        prec = correct[t] / total_predicted\n",
        "        recl = correct[t] / total_observed\n",
        "        try:\n",
        "            f = 2 * prec * recl / (prec + recl)\n",
        "        except ZeroDivisionError:\n",
        "            f = 0\n",
        "        print('%s Correct: %d' % (t, correct[t]))\n",
        "        print('%s F score: %.4f (Precision: %.4f, Recall: %.4f)' % (t, f, prec, recl))\n",
        "        print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oZ4XnvrcmDmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "ddd94f8e-92fa-4beb-88bc-30813fd68aa3"
      },
      "cell_type": "code",
      "source": [
        "for lan in [\"CN\", \"EN\", \"SG\", \"FR\"]:\n",
        "\n",
        "    data = data_tuple(lan + \"/train\")\n",
        "    new_data = smoothing_em(data,1)[0]\n",
        "    words = smoothing_em(data,1)[1].keys()\n",
        "    tags = emission_parameter(data)[0].keys()\n",
        "    smoothed_em = emission_parameter(new_data)[2]\n",
        "    \n",
        "    tag_predict(lan,\"2\",words, tags, smoothed_em)\n",
        "    \n",
        "    with open(lan + '/dev.p2.out' ) as f:\n",
        "        pred = get_entities(f)\n",
        "    with open(lan + '/dev.out' ) as f:\n",
        "        gold = get_entities(f)\n",
        "        \n",
        "    print(lan)\n",
        "    compare_result(gold, pred)\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CN\n",
            "Entities:\n",
            "In gold-standard outputs: 1081\n",
            "In prediction outputs: 3963\n",
            "\n",
            "Entities Correct: 485\n",
            "Entities F score: 0.1923 (Precision: 0.1224, Recall: 0.4487)\n",
            "\n",
            "Sentiment Correct: 347\n",
            "Sentiment F score: 0.1376 (Precision: 0.0876, Recall: 0.3210)\n",
            "\n",
            "EN\n",
            "Entities:\n",
            "In gold-standard outputs: 802\n",
            "In prediction outputs: 770\n",
            "\n",
            "Entities Correct: 489\n",
            "Entities F score: 0.6221 (Precision: 0.6351, Recall: 0.6097)\n",
            "\n",
            "Sentiment Correct: 448\n",
            "Sentiment F score: 0.5700 (Precision: 0.5818, Recall: 0.5586)\n",
            "\n",
            "SG\n",
            "Entities:\n",
            "In gold-standard outputs: 4092\n",
            "In prediction outputs: 9283\n",
            "\n",
            "Entities Correct: 1999\n",
            "Entities F score: 0.2989 (Precision: 0.2153, Recall: 0.4885)\n",
            "\n",
            "Sentiment Correct: 1179\n",
            "Sentiment F score: 0.1763 (Precision: 0.1270, Recall: 0.2881)\n",
            "\n",
            "FR\n",
            "Entities:\n",
            "In gold-standard outputs: 238\n",
            "In prediction outputs: 826\n",
            "\n",
            "Entities Correct: 175\n",
            "Entities F score: 0.3289 (Precision: 0.2119, Recall: 0.7353)\n",
            "\n",
            "Sentiment Correct: 78\n",
            "Sentiment F score: 0.1466 (Precision: 0.0944, Recall: 0.3277)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}